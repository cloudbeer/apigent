from fastapi import APIRouter, HTTPException, Header
from fastapi.responses import StreamingResponse
import logging
from app.utils.retrieve import retrieve_tools_by_text
from app.utils.preproccess import get_tool_schema
from pydantic import BaseModel
from typing import List, Optional, AsyncGenerator
from app.utils.pg import query_one_dict, execute_dict, create, update, delete, detail, list_all, execute_none
from app.utils.ai import parse_tool_schemas, parse_tool_schemas_stream
from app.models.chat import ChatSessionCreate, ChatHistoryCreate
import json
import uuid
import time
# from psycopg.types.json import Jsonb
# from openai.types.chat import ChatCompletionMessage

logger = logging.getLogger(__name__)    

router = APIRouter()

class Message(BaseModel):
    role: str
    content: str

class ChatCompletionRequest(BaseModel):
    messages: List[Message]
    temperature: Optional[float] = 0.7
    max_tokens: Optional[int] = 1000
    stream: Optional[bool] = False

# @router.post("/")
# async def chat(request: ChatCompletionRequest):
#     user_messages = [msg.content for msg in request.messages if msg.role == "user"]
#     if not user_messages:
#         raise HTTPException(status_code=400, detail="No user message found in the request")
    
#     text = user_messages[-1]
#     logger.info(f"Received chat request: {text}")
#     """
#     æ ¹æ®ç”¨æˆ·è¾“å…¥çš„æ–‡æœ¬æ£€ç´¢ç›¸å…³çš„å·¥å…·
    
#     Args:
#         text: ç”¨æˆ·è¾“å…¥çš„æŸ¥è¯¢æ–‡æœ¬
        
#     Returns:
#         List[Dict[str, Any]]: åŒ¹é…çš„å·¥å…·åˆ—è¡¨
#     """
#     try:
#         # è°ƒç”¨æ£€ç´¢å‡½æ•°è·å–ç›¸å…³å·¥å…·
#         tools = retrieve_tools_by_text(text, similarity_threshold=0.4)
#         for tool in tools:
#             logger.info(f"Tool: {tool}")
#             tool_schema = get_tool_schema(tool["id"])
#             return {"tools": [tool_schema]}
#         return {"tools": []}
#     except Exception as e:
#         logger.error(f"Error in chat endpoint: {str(e)}")
#         raise HTTPException(status_code=500, detail=str(e))





@router.post("/completions")
async def chat_completions(
    request: ChatCompletionRequest,
    session_id: str = Header(..., alias="Session-Id"),
    tool: str | None = Header(None, alias="Tool")
):
    if not session_id:
        raise HTTPException(status_code=400, detail="Session-Id is required")
    
    # æ£€æŸ¥ä¼šè¯çŠ¶æ€
    session = query_one_dict(
        "SELECT status FROM apigent_chat_session WHERE session_id = %s",
        (session_id,)
    )
    
    if session:
        # ä¼šè¯å­˜åœ¨ï¼Œæ£€æŸ¥çŠ¶æ€
        if session["status"] == 1:
            raise HTTPException(status_code=400, detail="Session is already completed")
    else:
        # ä¼šè¯ä¸å­˜åœ¨ï¼Œåˆ›å»ºæ–°ä¼šè¯
        create("apigent_chat_session", ChatSessionCreate(
            session_id=session_id,
            title=f"ä¼šè¯ {str(uuid.uuid4())[:8]}",
            status=0
        ))
    
    # æå–ç”¨æˆ·æ¶ˆæ¯
    user_messages = [msg for msg in request.messages if msg.role == "user"]
    if not user_messages:
        raise HTTPException(status_code=400, detail="No user message found in the request")
    
    # è·å–æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯
    # user_text = user_messages[-1].content
    # combile all user messages with weights
    user_text = ""
    total_weight = 0
    for i, msg in enumerate(user_messages):
        # ä½¿ç”¨æŒ‡æ•°è¡°å‡ï¼Œæœ€è¿‘çš„æ¶ˆæ¯æƒé‡æ›´é«˜
        weight = 2 ** (len(user_messages) - i - 1)
        user_text += msg.content + "\n" * weight
        total_weight += weight
    
    try:
        # è°ƒç”¨æ£€ç´¢å‡½æ•°è·å–ç›¸å…³å·¥å…·
        tools = retrieve_tools_by_text(user_text, similarity_threshold=0.4)
        tool_schemas = []
        used_tool_name = None
        parameters = None
        
        for tool in tools:
            logger.info(f"Tool: {tool}")
            tool_schema = get_tool_schema(tool["id"])
            tool_schemas.append(tool_schema)
            # å¦‚æœæœ‰å·¥å…·è¢«ä½¿ç”¨ï¼Œè®°å½•ç¬¬ä¸€ä¸ªå·¥å…·çš„åç§°
            if not used_tool_name and tool:
                used_tool_name = tool.get("name")
                # å¦‚æœæœ‰å‚æ•°ï¼Œä¹Ÿè®°å½•ä¸‹æ¥
                if "parameters" in tool:
                    parameters = tool.get("parameters")

        # æ‰“å°å·¥å…·ç»“æœ
        logger.info("å·¥å…·ç»“æœ:")
        logger.info(json.dumps(tool_schemas, ensure_ascii=False, indent=2))
        
        # ä¿å­˜ç”¨æˆ·è¯·æ±‚åˆ°èŠå¤©å†å²
        chat_history_create = ChatHistoryCreate(
            session_id=session_id,
            request_content={"messages": request.messages},
            # request_content=Jsonb({"messages": [msg.model_dump() for msg in request.messages]}),
            tool_name=used_tool_name,
            parameters=parameters
        )

        # print(chat_history_create)
        
        # åˆ›å»ºèŠå¤©å†å²è®°å½•
        history_record = create("apigent_chat_history", chat_history_create)
        history_id = history_record["id"]
        print(history_id)
        
        # è·å–AIå“åº”
        response = parse_tool_schemas(request.messages, tool_schemas)
        
        # æ£€æŸ¥å“åº”ä¸­æ˜¯å¦åŒ…å«å·¥å…·è°ƒç”¨ä¿¡æ¯
        if response and "openai_response" in response:
            openai_response = response["openai_response"]
            if "choices" in openai_response and len(openai_response["choices"]) > 0:
                choice = openai_response["choices"][0]
                if "message" in choice and "tool_calls" in choice["message"]:
                    tool_calls = choice["message"]["tool_calls"]
                    if tool_calls and len(tool_calls) > 0:
                        # è·å–ç¬¬ä¸€ä¸ªå·¥å…·è°ƒç”¨
                        tool_call = tool_calls[0]
                        if "function" in tool_call:
                            # æ›´æ–°å·¥å…·åç§°å’Œå‚æ•°
                            used_tool_name = tool_call["function"].get("name")
                            parameters_str = tool_call["function"].get("arguments")
                            
                            # å°è¯•è§£æå‚æ•°JSON
                            try:
                                parameters = json.loads(parameters_str) if parameters_str else None
                            except:
                                parameters = parameters_str
                            
                            # æ›´æ–°èŠå¤©å†å²è®°å½•ä¸­çš„å·¥å…·ä¿¡æ¯
                            execute_none(
                                "UPDATE apigent_chat_history SET tool_name = %s, parameters = %s WHERE id = %s",
                                (used_tool_name, json.dumps(parameters) if parameters else None, history_id)
                            )
        
        # æ›´æ–°èŠå¤©å†å²è®°å½•ï¼Œæ·»åŠ AIå“åº”
        execute_none(
            "UPDATE apigent_chat_history SET response_content = %s, updated_at = CURRENT_TIMESTAMP WHERE id = %s",
            (json.dumps(response), history_id)
        )
        
        # æ›´æ–°ä¼šè¯çš„æ›´æ–°æ—¶é—´
        execute_none(
            "UPDATE apigent_chat_session SET updated_at = CURRENT_TIMESTAMP WHERE session_id = %s",
            (session_id,)
        )
        
        # ç›´æ¥è¿”å› OpenAI çš„å“åº”
        return response
    except Exception as e:
        logger.error(f"Error in chat endpoint: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/completions/stream")
async def chat_completions_stream(
    request: ChatCompletionRequest,
    session_id: str = Header(..., alias="Session-Id"),
    tool: str | None = Header(None, alias="Tool")
):
    """
    æµå¼èŠå¤©å®ŒæˆAPI
    æ”¯æŒServer-Sent Events (SSE)æ ¼å¼çš„æµå¼å“åº”
    """
    if not session_id:
        raise HTTPException(status_code=400, detail="Session-Id is required")
    
    # æ£€æŸ¥ä¼šè¯çŠ¶æ€
    session = query_one_dict(
        "SELECT status FROM apigent_chat_session WHERE session_id = %s",
        (session_id,)
    )
    
    if session:
        # ä¼šè¯å­˜åœ¨ï¼Œæ£€æŸ¥çŠ¶æ€
        if session["status"] == 1:
            raise HTTPException(status_code=400, detail="Session is already completed")
    else:
        # ä¼šè¯ä¸å­˜åœ¨ï¼Œåˆ›å»ºæ–°ä¼šè¯
        create("apigent_chat_session", ChatSessionCreate(
            session_id=session_id,
            title=f"ä¼šè¯ {str(uuid.uuid4())[:8]}",
            status=0
        ))
    
    # æå–ç”¨æˆ·æ¶ˆæ¯
    user_messages = [msg for msg in request.messages if msg.role == "user"]
    if not user_messages:
        raise HTTPException(status_code=400, detail="No user message found in the request")
    
    # è·å–æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯
    user_text = ""
    total_weight = 0
    for i, msg in enumerate(user_messages):
        # ä½¿ç”¨æŒ‡æ•°è¡°å‡ï¼Œæœ€è¿‘çš„æ¶ˆæ¯æƒé‡æ›´é«˜
        weight = 2 ** (len(user_messages) - i - 1)
        user_text += msg.content + "\n" * weight
        total_weight += weight
    
    async def generate_stream() -> AsyncGenerator[str, None]:
        history_id = None
        complete_response = {
            "openai_response": {
                "id": f"chatcmpl-{uuid.uuid4().hex[:29]}",
                "object": "chat.completion",
                "created": int(time.time()),
                "model": "",
                "choices": [{
                    "index": 0,
                    "message": {
                        "role": "assistant",
                        "content": "",
                        "tool_calls": []
                    },
                    "finish_reason": None
                }],
                "usage": {
                    "prompt_tokens": 0,
                    "completion_tokens": 0,
                    "total_tokens": 0
                }
            },
            "timestamp": int(time.time()),
            "model": "",
            "tools_used": []
        }
        
        try:
            # è°ƒç”¨æ£€ç´¢å‡½æ•°è·å–ç›¸å…³å·¥å…·
            tools = retrieve_tools_by_text(user_text, similarity_threshold=0.4)
            tool_schemas = []
            used_tool_name = None
            parameters = None
            
            for tool in tools:
                logger.info(f"Tool: {tool}")
                tool_schema = get_tool_schema(tool["id"])
                tool_schemas.append(tool_schema)
                # å¦‚æœæœ‰å·¥å…·è¢«ä½¿ç”¨ï¼Œè®°å½•ç¬¬ä¸€ä¸ªå·¥å…·çš„åç§°
                if not used_tool_name and tool:
                    used_tool_name = tool.get("name")
                    # å¦‚æœæœ‰å‚æ•°ï¼Œä¹Ÿè®°å½•ä¸‹æ¥
                    if "parameters" in tool:
                        parameters = tool.get("parameters")

            # æ‰“å°å·¥å…·ç»“æœ
            logger.info("å·¥å…·ç»“æœ:")
            logger.info(json.dumps(tool_schemas, ensure_ascii=False, indent=2))
            
            # ä¿å­˜ç”¨æˆ·è¯·æ±‚åˆ°èŠå¤©å†å²
            chat_history_create = ChatHistoryCreate(
                session_id=session_id,
                request_content={"messages": request.messages},
                tool_name=used_tool_name,
                parameters=parameters
            )
            
            # åˆ›å»ºèŠå¤©å†å²è®°å½•
            history_record = create("apigent_chat_history", chat_history_create)
            history_id = history_record["id"]
            
            # å‡†å¤‡å·¥å…·ä½¿ç”¨ä¿¡æ¯
            tools_used = [{"name": tool["function"]["name"], "key": tool["function"]["key"]} for tool in tool_schemas] if tool_schemas else []
            complete_response["tools_used"] = tools_used
            
            # é¦–å…ˆå‘é€å·¥å…·ä½¿ç”¨ä¿¡æ¯
            if tools_used:
                tools_info = {
                    "tools_used": tools_used,
                    "timestamp": int(time.time()),
                    "type": "tools_info"
                }
                yield f"data: {json.dumps(tools_info, ensure_ascii=False)}\n\n"
            
            # è·å–æµå¼AIå“åº” - ç«‹å³è½¬å‘ï¼Œä¸åšé˜»å¡å¤„ç†
            async for chunk in parse_tool_schemas_stream(request.messages, tool_schemas):
                # ç«‹å³å‘é€æ¯ä¸ªchunkï¼Œä¸åšä»»ä½•å¤„ç†
                if "error" in chunk:
                    yield f"data: {json.dumps(chunk, ensure_ascii=False)}\n\n"
                    yield "data: [DONE]\n\n"
                    return
                
                # ğŸš€ å…³é”®ï¼šç«‹å³å‘é€SSEæ ¼å¼çš„æ•°æ®ï¼Œä¸åšä»»ä½•é˜»å¡å¤„ç†
                chunk_json = json.dumps(chunk, ensure_ascii=False)
                yield f"data: {chunk_json}\n\n"
                
                # å¼‚æ­¥å¤„ç†æ•°æ®æ”¶é›†ï¼Œä¸é˜»å¡æµå¼è¾“å‡º
                try:
                    # æ›´æ–°å®Œæ•´å“åº”ç”¨äºåç»­æ•°æ®åº“ä¿å­˜ï¼ˆå¼‚æ­¥å¤„ç†ï¼‰
                    if "choices" in chunk and len(chunk["choices"]) > 0:
                        choice = chunk["choices"][0]
                        if "delta" in choice:
                            delta = choice["delta"]
                            
                            # æ›´æ–°å†…å®¹
                            if "content" in delta and delta["content"]:
                                complete_response["openai_response"]["choices"][0]["message"]["content"] += delta["content"]
                            
                            # æ›´æ–°å·¥å…·è°ƒç”¨
                            if "tool_calls" in delta:
                                for tool_call_delta in delta["tool_calls"]:
                                    if "index" in tool_call_delta:
                                        index = tool_call_delta["index"]
                                        # ç¡®ä¿å·¥å…·è°ƒç”¨åˆ—è¡¨æœ‰è¶³å¤Ÿçš„å…ƒç´ 
                                        while len(complete_response["openai_response"]["choices"][0]["message"]["tool_calls"]) <= index:
                                            complete_response["openai_response"]["choices"][0]["message"]["tool_calls"].append({
                                                "id": "",
                                                "type": "function",
                                                "function": {"name": "", "arguments": ""}
                                            })
                                        
                                        # æ›´æ–°å·¥å…·è°ƒç”¨ä¿¡æ¯
                                        if "id" in tool_call_delta:
                                            complete_response["openai_response"]["choices"][0]["message"]["tool_calls"][index]["id"] = tool_call_delta["id"]
                                        if "function" in tool_call_delta:
                                            func_delta = tool_call_delta["function"]
                                            if "name" in func_delta:
                                                complete_response["openai_response"]["choices"][0]["message"]["tool_calls"][index]["function"]["name"] += func_delta["name"]
                                            if "arguments" in func_delta:
                                                complete_response["openai_response"]["choices"][0]["message"]["tool_calls"][index]["function"]["arguments"] += func_delta["arguments"]
                            
                            # æ›´æ–°å®ŒæˆåŸå› 
                            if "finish_reason" in choice:
                                complete_response["openai_response"]["choices"][0]["finish_reason"] = choice["finish_reason"]
                    
                    # æ›´æ–°æ¨¡å‹ä¿¡æ¯
                    if "model" in chunk:
                        complete_response["openai_response"]["model"] = chunk["model"]
                        complete_response["model"] = chunk["model"]
                    
                    # æ›´æ–°ä½¿ç”¨ç»Ÿè®¡
                    if "usage" in chunk:
                        complete_response["openai_response"]["usage"] = chunk["usage"]
                        
                except Exception as process_error:
                    # æ•°æ®å¤„ç†é”™è¯¯ä¸åº”è¯¥å½±å“æµå¼è¾“å‡º
                    logger.warning(f"Chunk processing error: {str(process_error)}")
                    continue
            
            # å‘é€ç»“æŸæ ‡è®°
            yield "data: [DONE]\n\n"
            
        except Exception as e:
            logger.error(f"Error in streaming chat endpoint: {str(e)}")
            error_data = {
                "error": {
                    "message": str(e),
                    "type": "internal_error",
                    "code": "stream_error"
                }
            }
            yield f"data: {json.dumps(error_data, ensure_ascii=False)}\n\n"
            yield "data: [DONE]\n\n"
        finally:
            # åœ¨finallyå—ä¸­å¤„ç†æ•°æ®åº“æ›´æ–°ï¼Œé¿å…é˜»å¡æµå¼è¾“å‡º
            if history_id:
                try:
                    # å¤„ç†å·¥å…·è°ƒç”¨ä¿¡æ¯å¹¶æ›´æ–°æ•°æ®åº“
                    if complete_response["openai_response"]["choices"][0]["message"]["tool_calls"]:
                        tool_calls = complete_response["openai_response"]["choices"][0]["message"]["tool_calls"]
                        if tool_calls and len(tool_calls) > 0:
                            # è·å–ç¬¬ä¸€ä¸ªå·¥å…·è°ƒç”¨
                            tool_call = tool_calls[0]
                            if "function" in tool_call:
                                # æ›´æ–°å·¥å…·åç§°å’Œå‚æ•°
                                used_tool_name = tool_call["function"].get("name")
                                parameters_str = tool_call["function"].get("arguments")
                                
                                # å°è¯•è§£æå‚æ•°JSON
                                try:
                                    parameters = json.loads(parameters_str) if parameters_str else None
                                except:
                                    parameters = parameters_str
                                
                                # æ›´æ–°èŠå¤©å†å²è®°å½•ä¸­çš„å·¥å…·ä¿¡æ¯
                                execute_none(
                                    "UPDATE apigent_chat_history SET tool_name = %s, parameters = %s WHERE id = %s",
                                    (used_tool_name, json.dumps(parameters) if parameters else None, history_id)
                                )
                    
                    # æ›´æ–°èŠå¤©å†å²è®°å½•ï¼Œæ·»åŠ AIå“åº”
                    execute_none(
                        "UPDATE apigent_chat_history SET response_content = %s, updated_at = CURRENT_TIMESTAMP WHERE id = %s",
                        (json.dumps(complete_response), history_id)
                    )
                    
                    # æ›´æ–°ä¼šè¯çš„æ›´æ–°æ—¶é—´
                    execute_none(
                        "UPDATE apigent_chat_session SET updated_at = CURRENT_TIMESTAMP WHERE session_id = %s",
                        (session_id,)
                    )
                except Exception as db_error:
                    logger.error(f"Database update error: {str(db_error)}")
    
    return StreamingResponse(
        generate_stream(),
        media_type="text/plain",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "Content-Type": "text/plain; charset=utf-8"
        }
    )

